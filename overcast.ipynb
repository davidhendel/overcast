{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"insight_logo.png\" ALIGN=left style=\"margin: 0px 30px 30px 0px;\" width=\"120\"/> <font size=\"6\"> Interview Demo: **overcast** </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Just a few decades ago it was common for many astronomers to spend a significant fraction of their careers sitting behind the eyepiece of a telescope. Now the field is moving towards a model where most astronomers use data from a few billion-dollar telescopes in space or on near-perfect mountaintop sites that observe with more and more autonomy. \n",
    "\n",
    "One of the remaining crucial uses of (relatively) small-format telescopes is the rapid prototyping of new technologies. A flagship example is Dragonfly, shown below, a 1-meter class telescope built from an array of 48 commercial Canon telephoto lenses with specialized optical coatings.\n",
    "\n",
    "<img src=\"dragonfly.jpg\" ALIGN=left style=\"margin: 0px 10px 0px 0px;\" width=\"300\"/> \n",
    "\n",
    "Dragonfly has made many amazing discoveries but its team is just three professors and a handful of postdocs, graduate students, and undergraduates. One of them must be awake to observe (remotely) on the telescope every night, so they too have been moving towards a fully automated observing pipeline and have optimized for e.g. target selection as a function of position on sky and survey priority. \n",
    "\n",
    "A remaning roadblock to full autonomy - and a good night's sleep for all! - is the weather. Dragonfly has a good location but compared to that of billion-dollar class instruments the site's weather is quite variable. The observatory has an all-sky cloud sensor, meaning that stopping observations for overcast conditions could forego valueable data collection while a portion of the sky is clear. The site also has a webcam that the observer can use to modify the scheduling. Here we use machine learning to accomplish that task, building classification and prediction tools that the telescope's scheduler can query to adapt to the site conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "1. Determine where a target lies on the webcam image\n",
    "2. Decide whether that part of the image is cloudy\n",
    "3. Predict if its status will change in the next ten minutes (Dragonfly's basic time unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "<img src=\"2020-04-06/hires_04h12m22s_2020-04-07_EDT.jpg\" ALIGN=left style=\"margin: 0px 10px 0px 0px;\" width=\"400\"/>  The epoch data are three images from the New Mexico Skies site website consisting of a high-resolution all-sky image, a low-resolution all-sky image, and a plot of the cloud sensor reading for the last few hours. The low-resoution image has only 1/10 as many pixels and tends to have more internal reflections but the high-resolution image seems less reliable, sometimes not changing over hours with seemingly no reason. We poll the website for these images every minute during the night. A typical high-res image is shown at left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data access \n",
    "\n",
    "Spawn a subprocess to fetch the images and put them in a folder for today's date; this will run through the night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = time.strftime('%Y-%m-%d')\n",
    "#Popen is non-blocking\n",
    "#Toggle this statement - careful of opening a bunch of instances\n",
    "if False: imgetter = subprocess.Popen([\"python\", \"get_images.py\", today])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imgetter.returncode)\n",
    "imgetter.kill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching pixels to sky positions\n",
    "\n",
    "To decide whether a target is in clear sky we must first map sky positions to pixel coordinates. Typical astronomical images from e.g. the *Hubble Space Telescope* cover only a small area and so this transformation can be excellently approximated using the image tangent plane, one-to-one. However, it is apparent from inspection that the camera has a 'circular fisheye' lens - the image circle is inscribed within the sensor area, and there is a substantial (intentional) distortion from the usual mapping relations. \n",
    "\n",
    "Equisolid angle fisheyes are the most common comercially and have the useful property that each pixel covers the same area of sky. Here we assume this is the case for the New Mexico Skies fisheye; our results below lend confidence to this. For equisolid angle lenses, the mapping between the radius $r$ in pixels from the center of the frame and the angle $\\theta$ from the optical axis is\n",
    "\n",
    "$r = k_1 f \\sin(\\theta/k_2)$\n",
    "\n",
    "where $k_{1}$ and $k_{2}$ depend on details of the lense shape and $f$ is a function of the sensor size and pixel scale.\n",
    "\n",
    "Sky positions and other data about stars likely visible to the camera was obtained from the Yale Bright Star Catalog (Dorrit & Carlos 1991), which contains 9,095 stars and approximates all those visibile with the naked eye. We identified  a subset of bright stars in the high-resolution images for three recongiziable constellations - Scorpio, Ursa Major, and Lyra - to compare their pixel positions with those calculated using the catalog, location, and time of day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ce22d8c52b4a0ca2ced72a0074ee46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from camera_mapping import star_pos_check\n",
    "star_pos_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have transformed the catalog positions to pixel coordinates using the equation above, assuming that the optical axis is pointed exactly at the zenith at that the top of the figure is pointed North, as specified by NMSkies. We take fiducial values $f=900$ and $k_1=k_2=2$. While the inferred positions (blue) are relatively close to the observed positions (red), clearly there is an important and nontrivial offset (not a rotation or translation) missing.\n",
    "\n",
    "To identify the true mapping we use an affine-invariant Markov Chain Monte Carlo ensemble sampler called *emcee*, implemented in pure Python (Foreman-Mackey et al. 2013). We have six model parameters - $f,\\ k_1,\\ k_2$, the camera rotation East of North, and the pixel coordinates that represents the zenith. However, $f$ and $k_1$ are highly degenerate since they appear only multiplied with eachother, so we reduce the dimensinality by considering $f\\times k_1 $, the 'scaling', instead. The likelihood function is the Euclidian distance between observed positions and mapped positions, and we assume wide Gaussian priors on all but $k_1$ and $k_2$, for which we use a uniform distribution between 1 and 3.\n",
    "\n",
    "Below we show a corner plot representing the 1-d and 2-d marginalized likelihoods for each parameter.\n",
    "\n",
    "<img src=\"corner_plot_2.png\" style=\"margin: 10px 10px 10px 10px;\" width=\"600\"/> \n",
    "\n",
    "The parameters are extremely well constrained. The scaling and $k_2$ are significantly correlated but the fractional uncertainty in both is quite small. The zenith position is determined to less than a pixel and the rotation to a few hundredths of a degree. As shown below, the match between positions is immensely better (note that Lyra is shown at a larger relative scale). Further improvements will accouting for e.g. atmospheric refraction can produce only negligble progress towards the goal of cloudiness forecasts for a particular part of the sky.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc1ce3e0c47494dbc52410779c27273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "star_pos_check(scalefac = 2141.4, rot = 4.58, k2=2.30, xc = 1969.5, yc = 1371.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data properties\n",
    "\n",
    "In this section we examine the images to identify features to use for classification.\n",
    "\n",
    "Unfortunately this week the moon is up which complicates things - this is normally considered suboptimal observing conditions but we will make do. The central 1600x1600 pixel area would be nice but here we use the top half of it to remove most of the Moon's influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf869f559a44f70948e00806b3dcb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dfa62e516645c4844cc3c3ccdfb547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0.98,'Cloudy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloudy_filenames=[\n",
    "'2020-04-06/hires_00h01m58s_2020-04-07_EDT.jpg',\n",
    "'2020-04-06/hires_00h06m08s_2020-04-07_EDT.jpg',\n",
    "'2020-04-06/hires_00h11m20s_2020-04-07_EDT.jpg',\n",
    "'2020-04-06/hires_00h18m35s_2020-04-07_EDT.jpg',\n",
    "'2020-04-06/hires_00h24m49s_2020-04-07_EDT.jpg',\n",
    "'2020-04-06/hires_04h06m08s_2020-04-07_EDT.jpg',\n",
    "'2020-04-06/hires_04h12m22s_2020-04-07_EDT.jpg',\n",
    "'2020-04-06/hires_04h17m34s_2020-04-07_EDT.jpg',\n",
    "'2020-04-06/hires_04h22m47s_2020-04-07_EDT.jpg',\n",
    "'2020-04-06/hires_04h28m00s_2020-04-07_EDT.jpg',\n",
    "]\n",
    "\n",
    "clear_filenames=[\n",
    "'2020-04-02/hires_05h04m11s_2020-04-03_EDT.jpg',\n",
    "'2020-04-02/hires_05h09m13s_2020-04-03_EDT.jpg',\n",
    "'2020-04-02/hires_05h14m17s_2020-04-03_EDT.jpg',\n",
    "'2020-04-02/hires_05h19m20s_2020-04-03_EDT.jpg',\n",
    "'2020-04-02/hires_05h24m23s_2020-04-03_EDT.jpg',\n",
    "]\n",
    "\n",
    "#no moon\n",
    "#clear_filenames=[\n",
    "#'2020-04-03/hires_06h54m10s_2020-04-04_EDT.jpg',\n",
    "#'2020-04-03/hires_07h00m33s_2020-04-04_EDT.jpg',\n",
    "#'2020-04-03/hires_07h04m48s_2020-04-04_EDT.jpg',\n",
    "#'2020-04-03/hires_07h10m09s_2020-04-04_EDT.jpg',\n",
    "#'2020-04-03/hires_07h17m36s_2020-04-04_EDT.jpg',\n",
    "#]\n",
    "\n",
    "plt.figure()\n",
    "for i in np.arange(4):\n",
    "    plt.subplot(2,2,i+1)\n",
    "    plt.imshow(plt.imread(clear_filenames[i])[536:2136,1204:2804,0], cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.suptitle('Clear')\n",
    "plt.figure()\n",
    "for i in np.arange(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(plt.imread(cloudy_filenames[i])[536:2136,1204:2804,0], vmax=170, cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.suptitle('Cloudy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the pixel value histograms to get a better idea of the difference between the clear and cloudy images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a324564f51843a4bc9914168ecd43fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Standard deviation of pixel values')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot histograms of pixel values\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "for i in np.arange(4):\n",
    "    clear_artist = plt.hist(plt.imread(clear_filenames[i])[536:1336,1204:2804,0].flatten(), \n",
    "                            color='k', bins=50, log=True, histtype='step', lw=3, alpha=.5)\n",
    "for i in np.arange(9):\n",
    "    cloudy_artist = plt.hist(plt.imread(cloudy_filenames[i])[536:1336,1204:2804,0].flatten(), \n",
    "                            color='r', bins=50, log=True, histtype='step', lw=3, alpha=.5)\n",
    "plt.ylabel('Pixel counts')\n",
    "plt.xlabel('Pixel values')\n",
    "plt.legend((clear_artist[-1][0], cloudy_artist[-1][0]), ('Clear', 'Cloudy'))\n",
    "\n",
    "#plot some global statistics\n",
    "plt.subplot(122)\n",
    "for i in np.arange(5):\n",
    "    im_clear  = plt.imread(clear_filenames[i])[536:1336,1204:2804,0]\n",
    "    cal = np.resize(np.median(plt.imread(clear_filenames[i])[536:1336,0:500,0],axis=1),(1600,800)).T\n",
    "    clear_vals  = (im_clear-cal).flatten()\n",
    "    clear_artist = plt.scatter(np.median(clear_vals), np.std(clear_vals), c='k', s=20)\n",
    "        \n",
    "for i in np.arange(10):\n",
    "    im_cloudy = plt.imread(cloudy_filenames[i])[536:1336,1204:2804,0]\n",
    "    cloudy_vals  = im_cloudy.flatten()\n",
    "    cloudy_artist = plt.scatter(np.median(cloudy_vals), np.std(cloudy_vals), c='r', s=20)\n",
    "plt.legend((clear_artist, cloudy_artist), ('Clear', 'Cloudy'))\n",
    "plt.xlabel('Median pixel value')\n",
    "plt.ylabel('Standard deviation of pixel values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this clear fields the typical pixel value is around 12 with a long tail - pixels with stars - towards saturation at 255. The cloudy images have a wider distribution and much more variation in median value, which can be equal to or greater than that typical of clear fields.\n",
    "\n",
    "Since we eventually want to classify small areas on the sky we should look at subimages as well, using 80x80 pixel divisions. As a third descriptor for these subimages we compute the entropy, a measure of the statistical randomness. It is calculated from the normalized histogram $h$ as $-\\Sigma\\ h\\times\\ln(h)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7842024861431382cddbdb33030caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendel/anaconda2/envs/py37/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x137de5898>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.lib.stride_tricks import as_strided \n",
    "    \n",
    "def make_subims(im, size=80):\n",
    "    '''Segment image into subimages of size x size as a size x size x n array.'''\n",
    "    nsubim, rem = divmod(im.shape[0]*im.shape[1], size**2)\n",
    "    assert rem == 0, \"Image cannot be evenly divided that way\"\n",
    "    subims = as_strided(im, shape=(im.shape[0], im.shape[1], size, size), \n",
    "                        strides=im.strides+im.strides)[::size,::size].reshape(nsubim,size,size)\n",
    "    return subims\n",
    "    \n",
    "def entropy(subim):\n",
    "    '''Comput the Shannon entropy of an image'''\n",
    "    p = np.histogram(subim.flatten(),bins=np.linspace(0,255,256), density=True)[0]\n",
    "    return -sum(p[p>0]*np.log(p[p>0]))\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # #\n",
    "#plot some local statistics - divide into 80x80 patches\n",
    "plt.figure()\n",
    "for i in np.arange(5):\n",
    "    #clear\n",
    "    im  = plt.imread(clear_filenames[i])[:,:,0]\n",
    "    cal = np.resize(np.median(im[:,0:500],axis=1),(4008,2672)).T\n",
    "    im = (im-cal)[536:1336,1204:2804]\n",
    "    #trick to get subimages\n",
    "    subim  = as_strided(im, shape=(800, 1600, 80, 80), strides=im.strides+im.strides)[::80,::80].reshape(200,80,80)\n",
    "    entropyarr = np.zeros(len(subim))\n",
    "    for j in np.arange(len(subim)):\n",
    "        entropyarr[j] = entropy(subim[j])\n",
    "\n",
    "    plt.subplot(221)\n",
    "    clear_artist = plt.scatter(np.median(subim, axis=(1,2)), entropyarr, c='k', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.ylabel('Entropy')\n",
    "    plt.subplot(223)\n",
    "    plt.scatter(np.median(subim, axis=(1,2)), np.std(subim, axis=(1,2)), c='k', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.ylabel('Standard deviation')\n",
    "    plt.xlabel('Median')\n",
    "    plt.subplot(224)\n",
    "    plt.scatter(entropyarr, np.std(subim, axis=(1,2)), c='k', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.xlabel('Entropy')\n",
    "\n",
    "for i in np.arange(10):\n",
    "    #cloudy\n",
    "    im  = plt.imread(cloudy_filenames[i])[:,:,0]\n",
    "    cal = np.resize(np.median(im[:,0:500],axis=1),(4008,2672)).T\n",
    "    im = (im-cal)[536:1336,1204:2804]\n",
    "    #trick to get subimages\n",
    "    subim  = as_strided(im, shape=(800, 1600, 80, 80), strides=im.strides+im.strides)[::80,::80].reshape(200,80,80)\n",
    "    entropyarr = np.zeros(len(subim))\n",
    "    for j in np.arange(len(subim)):\n",
    "        entropyarr[j] = entropy(subim[j])\n",
    "        \n",
    "    plt.subplot(221)\n",
    "    cloudy_artist = plt.scatter(np.median(subim, axis=(1,2)), entropyarr, c='r', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.ylabel('Entropy')\n",
    "    plt.subplot(223)\n",
    "    plt.scatter(np.median(subim, axis=(1,2)), np.std(subim, axis=(1,2)), c='r', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.ylabel('Standard deviation')\n",
    "    plt.xlabel('Median')\n",
    "    plt.subplot(224)\n",
    "    plt.scatter(entropyarr, np.std(subim, axis=(1,2)), c='r', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.xlabel('Entropy')\n",
    "plt.legend((clear_artist, cloudy_artist), ('Clear', 'Cloudy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individual patches are also nicely distinct in median - standard deviation - entropy space.\n",
    "\n",
    "Let's try SVM to create a classifier. This has the advantage vs. e.g. k-nearest neightbor or k-means that all the data doens't have to be carried around later, we can just use the hypersurface if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2920"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "#Compute the features for each class\n",
    "entropyarr = np.zeros((15,200))\n",
    "stdarr = np.zeros((15,200))\n",
    "medianarr = np.zeros((15,200))\n",
    "classesarr = np.zeros((15,200))\n",
    "for i in np.arange(5):\n",
    "    im  = plt.imread(clear_filenames[i])[:,:,0]\n",
    "    cal = np.resize(np.median(im[:,0:500],axis=1),(4008,2672)).T\n",
    "    im = (im-cal)\n",
    "    im = im[536:1336,1204:2804]\n",
    "    subim  = as_strided(im, shape=(800, 1600, 80, 80), strides=im.strides+im.strides)[::80,::80].reshape(200,80,80)\n",
    "    for j in np.arange(len(subim)):\n",
    "        entropyarr[i][j] = entropy(subim[j])\n",
    "    stdarr[i] = np.std(subim, axis=(1,2))\n",
    "    medianarr[i] = np.median(subim, axis=(1,2))\n",
    "    classesarr[i] = np.zeros((200))\n",
    "for i in np.arange(10):\n",
    "    im  = plt.imread(cloudy_filenames[i])[:,:,0]\n",
    "    cal = np.resize(np.median(im[:,0:500],axis=1),(4008,2672)).T\n",
    "    #im = (im-cal)\n",
    "    im=im[536:1336,1204:2804]\n",
    "    subim  = as_strided(im, shape=(800, 1600, 80, 80), strides=im.strides+im.strides)[::80,::80].reshape(200,80,80)\n",
    "    for j in np.arange(len(subim)):\n",
    "        entropyarr[i+5][j] = entropy(subim[j])\n",
    "    stdarr[i+5] = np.std(subim, axis=(1,2))\n",
    "    medianarr[i+5] = np.median(subim, axis=(1,2))\n",
    "    classesarr[i+5] = np.ones((200))\n",
    "\n",
    "#reshape\n",
    "features = np.array([medianarr.flatten(), stdarr.flatten(),entropyarr.flatten()]).T\n",
    "classes = classesarr.flatten().T\n",
    "\n",
    "svm = SVC(gamma='auto')\n",
    "#double weight clear since we didn't uses as many\n",
    "weights = -(classes-2)\n",
    "svm.fit(features, classes, sample_weight=weights)\n",
    "\n",
    "#given the 3000 inputs, how many are predicted correctly?\n",
    "sum(svm.predict(features)==classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier seems to work correctly - skipping cross-validation etc. for time\n",
    "\n",
    "How about one of the mixed clear/cloudy images that we area actually interested in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendel/anaconda2/envs/py37/lib/python3.7/site-packages/matplotlib/pyplot.py:522: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6ffdd6b86947b9a183bc2943ec9069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc0a8201cc14f5db636e6e3299c5b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendel/anaconda2/envs/py37/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x14be449e8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed_filenames = ['2020-04-05/hires_05h52m59s_2020-04-06_EDT.jpg','2020-04-07/hires_00h27m23s_2020-04-08_EDT.jpg']\n",
    "mim = plt.imread(mixed_filenames[0])[350:1950,1300:2100,0]\n",
    "#mim = plt.imread(mixed_filenames[1])[536:1336,1204:2804]\n",
    "plt.figure()\n",
    "plt.imshow(mim,vmax=70,cmap='gray')\n",
    "\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # #\n",
    "#plot some local statistics - divide into 80x80 patches\n",
    "plt.figure()\n",
    "for i in np.arange(5):\n",
    "    #clear\n",
    "    im  = plt.imread(clear_filenames[i])[:,:,0]\n",
    "    cal = np.resize(np.median(im[:,0:500],axis=1),(4008,2672)).T\n",
    "    im = (im-cal)[536:1336,1204:2804]\n",
    "    #trick to get subimages\n",
    "    subim  = as_strided(im, shape=(800, 1600, 80, 80), strides=im.strides+im.strides)[::80,::80].reshape(200,80,80)\n",
    "    entropyarr = np.zeros(len(subim))\n",
    "    for j in np.arange(len(subim)):\n",
    "        entropyarr[j] = entropy(subim[j])\n",
    "\n",
    "    plt.subplot(221)\n",
    "    clear_artist = plt.scatter(np.median(subim, axis=(1,2)), entropyarr, c='k', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.ylabel('Entropy')\n",
    "    plt.subplot(223)\n",
    "    plt.scatter(np.median(subim, axis=(1,2)), np.std(subim, axis=(1,2)), c='k', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.ylabel('Standard deviation')\n",
    "    plt.xlabel('Median')\n",
    "    plt.subplot(224)\n",
    "    plt.scatter(entropyarr, np.std(subim, axis=(1,2)), c='k', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.xlabel('Entropy')\n",
    "\n",
    "for i in np.arange(10):\n",
    "    #cloudy\n",
    "    im  = plt.imread(cloudy_filenames[i])[:,:,0]\n",
    "    cal = np.resize(np.median(im[:,0:500],axis=1),(4008,2672)).T\n",
    "    im = (im-cal)[536:1336,1204:2804]\n",
    "    #trick to get subimages\n",
    "    subim  = as_strided(im, shape=(800, 1600, 80, 80), strides=im.strides+im.strides)[::80,::80].reshape(200,80,80)\n",
    "    entropyarr = np.zeros(len(subim))\n",
    "    for j in np.arange(len(subim)):\n",
    "        entropyarr[j] = entropy(subim[j])\n",
    "        \n",
    "    plt.subplot(221)\n",
    "    cloudy_artist = plt.scatter(np.median(subim, axis=(1,2)), entropyarr, c='r', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.ylabel('Entropy')\n",
    "    plt.subplot(223)\n",
    "    plt.scatter(np.median(subim, axis=(1,2)), np.std(subim, axis=(1,2)), c='r', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.ylabel('Standard deviation')\n",
    "    plt.xlabel('Median')\n",
    "    plt.subplot(224)\n",
    "    plt.scatter(entropyarr, np.std(subim, axis=(1,2)), c='r', alpha=0.4, s=10, edgecolor='none')\n",
    "    plt.xlabel('Entropy')\n",
    "    \n",
    "#mixed\n",
    "im  = plt.imread('2020-04-05/hires_05h52m59s_2020-04-06_EDT.jpg')[:,:,0]\n",
    "cal = np.resize(np.median(im[:,0:500],axis=1),(4008,2672)).T\n",
    "#im = (im-cal)\n",
    "im = im[536:2136,1204:2004]\n",
    "subim  = as_strided(im, shape=(1600, 800, 80, 80), strides=im.strides+im.strides)[::80,::80].reshape(200,80,80)\n",
    "\n",
    "\n",
    "#im = plt.imread(mixed_filenames[0])[:,:,0]\n",
    "#cal = np.resize(np.median(im[:,0:500],axis=1),(4008,2672)).T\n",
    "##im = im-cal\n",
    "#im = im[536:1336,1204:2804]\n",
    "#subim  = as_strided(im, shape=(800, 1600, 80, 80), strides=im.strides+im.strides)[::80,::80].reshape(200,80,80)\n",
    "\n",
    "\n",
    "entropyarr = np.zeros(len(subim))\n",
    "for j in np.arange(len(subim)):\n",
    "    entropyarr[j] = entropy(subim[j])\n",
    "\n",
    "plt.subplot(221)\n",
    "mixed_artist = plt.scatter(np.median(subim, axis=(1,2)), entropyarr, c='b', alpha=1, s=10, edgecolor='none')\n",
    "plt.ylabel('Entropy')\n",
    "plt.subplot(223)\n",
    "plt.scatter(np.median(subim, axis=(1,2)), np.std(subim, axis=(1,2)), c='b', alpha=1, s=10, edgecolor='none')\n",
    "plt.ylabel('Standard deviation')\n",
    "plt.xlabel('Median')\n",
    "plt.subplot(224)\n",
    "plt.scatter(entropyarr, np.std(subim, axis=(1,2)), c='b', alpha=1, s=10, edgecolor='none')\n",
    "plt.xlabel('Entropy')\n",
    "\n",
    "\n",
    "plt.legend((clear_artist, cloudy_artist, mixed_artist), ('Clear', 'Cloudy', 'Mixed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hendel/anaconda2/envs/py37/lib/python3.7/site-packages/matplotlib/pyplot.py:522: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb70c92c014407daf499a3e96e15e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to  previous…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1517b5f98>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropyarr = np.zeros((200))\n",
    "for j in np.arange(len(subim)):\n",
    "    entropyarr[j] = entropy(subim[j])\n",
    "stdarr = np.std(subim, axis=(1,2))\n",
    "medianarr = np.median(subim, axis=(1,2))\n",
    "\n",
    "mfeatures = np.array([medianarr.flatten(), stdarr.flatten(),entropyarr.flatten()]).T\n",
    "\n",
    "mclasses = svm.predict(mfeatures)\n",
    "mclassim = mclasses.reshape(20,10)\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(mim,vmax=30,vmin=0,cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(mclassim, vmin=0, vmax=1, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "There are definitley some inter-frame calibration issues remaining but clearly the above shows that the more-clear parts of the image are indeed classified mostly as being clear - a good start!\n",
    "\n",
    "To-do:\n",
    "- Write a wrapper to take a target list of (RA, Dec)s, do the transformation from section 1, then ask if it is in a clear part of the image using the SVM from section 2\n",
    "- Get observatory to upload frames more often!\n",
    " - Necessary to eventually predict the future; clouds move too far in 5m intervals\n",
    "- Improve image calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
